{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow versus Poisonous Mushrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "srooms_df = read_csv('../data/agaricus-lepiota.data.csv')\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "mappings = ([\n",
    "    ('edibility', sklearn.preprocessing.LabelEncoder()),\n",
    "    ('odor', sklearn.preprocessing.LabelBinarizer()),\n",
    "    ('habitat', sklearn.preprocessing.LabelBinarizer()),\n",
    "    ('spore-print-color', sklearn.preprocessing.LabelBinarizer())\n",
    "])\n",
    "\n",
    "mapper = DataFrameMapper(mappings)\n",
    "srooms_np = mapper.fit_transform(srooms_df.copy()).astype(np.float32)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(srooms_np, test_size = 0.2, random_state=7)\n",
    "train_labels = train[:,0:1]\n",
    "train_data = train[:,1:]\n",
    "test_labels = test[:,0:1]\n",
    "test_data = test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "def inference(samples, input_dim, dense1_units, dense2_units):\n",
    "    with tf.name_scope('dense_1'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([input_dim, dense1_units],\n",
    "                                stddev=1.0 / math.sqrt(float(input_dim))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(tf.zeros([dense1_units]),\n",
    "                             name='biases')\n",
    "        dense1 = tf.nn.relu(tf.nn.xw_plus_b(samples, weights, biases))\n",
    "        \n",
    "    with tf.name_scope('dropout'):\n",
    "        dropout = tf.nn.dropout(dense1, 0.5)\n",
    "        \n",
    "    with tf.name_scope('dense_2'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([dense1_units, dense2_units],\n",
    "                                stddev=1.0 / math.sqrt(float(dense2_units))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(tf.zeros([dense2_units]),\n",
    "                             name='biases')\n",
    "        logits = tf.sigmoid(tf.nn.xw_plus_b(dropout, weights, biases))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(logits, labels):\n",
    "  xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "  return tf.reduce_mean(xentropy)\n",
    "\n",
    "def predict(logits):\n",
    "    return tf.round(logits)\n",
    "\n",
    "def accuracy(logits, labels):\n",
    "    return tf.reduce_mean(tf.to_float(tf.equal(predict(logits),labels)))\n",
    "\n",
    "def training(loss):\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7149622440338135, accuracy: 0.520080029964447\n",
      "loss: 0.6092740297317505, accuracy: 0.8598245978355408\n",
      "loss: 0.5564351081848145, accuracy: 0.9478381276130676\n",
      "loss: 0.5363012552261353, accuracy: 0.9736882448196411\n",
      "loss: 0.5266803503036499, accuracy: 0.9856901168823242\n",
      "loss: 0.5221099257469177, accuracy: 0.9892290830612183\n",
      "loss: 0.5196435451507568, accuracy: 0.991844892501831\n",
      "loss: 0.5184599757194519, accuracy: 0.9924603700637817\n",
      "loss: 0.5171313285827637, accuracy: 0.9927681088447571\n",
      "loss: 0.5161339044570923, accuracy: 0.9933835864067078\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=train_data.shape)\n",
    "y = tf.placeholder(tf.float32, shape=train_labels.shape)\n",
    "\n",
    "logits = inference(x, 25, 20, 1)\n",
    "loss_op = loss(logits, y)\n",
    "predict_op = predict(logits)\n",
    "acc_op = accuracy(logits, y)\n",
    "train_op = training(loss_op)\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    epochs = 1000\n",
    "    for epoch in range(epochs):\n",
    "        _, loss_val, acc_val = sess.run([train_op, loss_op, acc_op], feed_dict={x: train_data, y: train_labels})\n",
    "        if epoch % 100 == 0:\n",
    "            print('loss: {}, accuracy: {}'.format(loss_val,acc_val))\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
